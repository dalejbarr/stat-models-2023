---
title: "Multiple Regression"
author: Dale Barr
institute: University of Glasgow
title-slide-attributes:
  data-background-image: ../img/titlescreen.png
format: 
  revealjs:
    code-line-numbers: false
knitr:
  opts_chunk:
    echo: true
---

```{r}
#| label: setup
#| include: false

options(tidyverse.quiet=TRUE)
library("lme4")
library("readxl")
library("tidyverse")

# options(width = 60)

set.seed(62)

dat <- read_excel("final_dataset.xlsx")

.cnames <- c("grade", "GPA", "lecture", "nclicks")
.cmx <- matrix(.3, nrow = 4, ncol = 4,
               dimnames = list(.cnames, .cnames))
diag(.cmx) <- 1
.sds <- c(1, 1, 2, 15)
for (i in 1:nrow(.cmx)) {
  for (j in 1:ncol(.cmx)) {
    .cmx[i, j] <- .cmx[i, j] * .sds[i] * .sds[j]
  }
}

.grades <- MASS::mvrnorm(100,
                         c(grade = 2.5, GPA = 2.5, lecture = 7, nclicks = 100),
                         .cmx) %>%
  as_tibble() %>%
  mutate(grade = case_when(grade < 0 ~ 0,
                           grade > 4 ~ 4,
                           TRUE ~ grade),
         GPA = case_when(GPA < 0 ~ 0,
                         GPA > 4 ~ 4,
                         TRUE ~ GPA),
         lecture = case_when(lecture < 0 ~ 0L,
                             lecture > 10 ~ 10L,
                             TRUE ~ as.integer(round(lecture))),
         nclicks = as.integer(round(nclicks)))

dir.create("data", FALSE)
write_csv(.grades, "data/grades.csv")
```

## Moving beyond simple regression

- dealing with multiple predictors
- model comparison
- coding categorical predictors

# Dealing with multiple predictors

## Multiple regression

General model for single-level data with $m$ predictors:

$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i$$

individual $X$s can be any combination of continuous and categorical predictors (and their interactions)

Each $\beta_j$ is the *partial effect of $X_{j}$ holding all other $X$s constant*

::: {.aside}
NB: single-level data is rare in psychology
:::

## Example

Are lecture attendance and engagement with online materials associated with higher grades in statistics?

Does this relationship hold after controlling for overall GPA?

## Import

[`grades.csv`](data/grades.csv){target="_download"}

```{r}
#| label: import-grades
#| output-location: fragment
grades <- read_csv("data/grades.csv", col_types = "ddii")

grades
```

## Correlations

```{r}
#| label: grades-corr
#| output-location: fragment
#| df-print: kable
library("corrr")

grades %>%
  correlate() %>%
  shave() %>%
  fashion()
```

## Visualization

```{r}
#| fig-width: 4
#| fig-height: 4
pairs(grades)
```

## Estimation

$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i$$

`lm(Y ~ X1 + X2 + ... + Xm, data)`

```{r}
my_model <- lm(grade ~ lecture + nclicks, grades)
```

## Output

```{r}
summary(my_model)
```

## Standardized coefficients

```{r}
#| label: standardize
#| output-location: slide
grades2 <- grades %>%
  mutate(lecture_c = (lecture - mean(lecture)) / sd(lecture),
         nclicks_c = (nclicks - mean(nclicks)) / sd(nclicks))

summary(lm(grade ~ lecture_c + nclicks_c, grades2))
```

# Model comparison

## Model comparison

Is engagement (as measured by lecture attendance and downloads) positively associated with final course grade *above and beyond* student ability (as measured by GPA)?

## Strategy

Compare "base" model with control vars to a "bigger" model with control plus focal vars

```{r}
#| output-location: fragment
base_model <- lm(grade ~ GPA, grades)
big_model <- lm(grade ~ GPA + lecture + nclicks, grades)

anova(base_model, big_model)
```

::: {.fragment}
$$F(2, 96) = 1.31, p = .275$$

If $p < \alpha$, bigger model is better.
:::

## `update()`

```{r}
#| label: model-compare
#| df-print: default
#| output-location: fragment
base_model <- lm(grade ~ GPA, grades)
big_model <- update(base_model, . ~ . +lecture +nclicks)

anova(base_model, big_model)
```

# Categorical predictors

## Dummy coding binary variables

$k = 2$

Arbitrarily assign one levels to 0; assign the other to 1.

```{r}
#| label: example
#| eval: false
dat |>
  mutate(dummy = if_else(predictor == "targetlevel", 1, 0))
```

See `dplyr::if_else()`

::: {.aside}
*NB: sign of the variable depends on the coding!*
:::

## Factors with $k > 2$

Arbitrarily choose one level as "baseline" level. Need $k - 1$ predictors, each contrasting a target level with baseline.

:::: {.columns}

::: {.column width="40%"}
$k = 3$

|       | `A2v1` | `A3v1` |
|-------+--------+--------|
| $A_1$ |      0 |      0 |
| $A_2$ |      1 |      0 |
| $A_3$ |      0 |      1 |
:::

::: {.column width="60%"}
$k = 4$

|       | `A2v1` | `A3v1` | `A4v1` |
|-------+--------+--------+--------|
| $A_1$ |      0 |      0 |      0 |
| $A_2$ |      1 |      0 |      0 |
| $A_3$ |      0 |      1 |      0 |
| $A_4$ |      0 |      0 |      1 |
:::

::::

## Bodyweight over the seasons

```{r}
#| label: bodyweight-sim
#| output-location: fragment
set.seed(1451)

season_wt <- tibble(season = rep(c("winter", "spring", "summer", "fall"),
                                 each = 5),
                    bodyweight_kg = c(rnorm(5, 105, 3),
                                      rnorm(5, 103, 3),
                                      rnorm(5, 101, 3),
                                      rnorm(5, 102.5, 3)))

season_wt
```

## Coding the predictor

```{r}
#| output-location: fragment
## baseline value is 'winter'
season_wt2 <- season_wt %>%
  mutate(spring_v_winter = if_else(season == "spring", 1, 0),
         summer_v_winter = if_else(season == "summer", 1, 0),
         fall_v_winter = if_else(season == "fall", 1, 0))

## ALWAYS double check using 'distinct'
season_wt2 |>
  distinct(season, spring_v_winter, summer_v_winter, fall_v_winter)
```
## Fitting the model

```{r}
#| output-location: fragment
mod <- lm(bodyweight_kg ~ spring_v_winter +
            summer_v_winter + fall_v_winter,
          season_wt2)

summary(mod)
```

## Main effect of season?

```{r}
#| output-location: fragment
mod_base <- lm(bodyweight_kg ~ 1, season_wt2)

anova(mod_base, mod)
```

## One-way Analysis of Variance

```{r}
#| output-location: fragment
season_wt3 <- season_wt2 %>%
  mutate(season = factor(season, levels = c("winter", "spring",
                                            "summer", "fall")))

my_anova <- aov(bodyweight_kg ~ season, season_wt3)
summary(my_anova)
```


